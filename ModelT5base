{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3723297,"sourceType":"datasetVersion","datasetId":2222120},{"sourceId":7639866,"sourceType":"datasetVersion","datasetId":841565},{"sourceId":9177835,"sourceType":"datasetVersion","datasetId":5546853},{"sourceId":9941146,"sourceType":"datasetVersion","datasetId":6112205},{"sourceId":9947105,"sourceType":"datasetVersion","datasetId":6116647}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install important library","metadata":{}},{"cell_type":"code","source":"pip install rouge-score sacrebleu evaluate torchsummary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T19:30:27.660512Z","iopub.execute_input":"2024-11-30T19:30:27.660895Z","iopub.status.idle":"2024-11-30T19:30:41.092143Z","shell.execute_reply.started":"2024-11-30T19:30:27.660858Z","shell.execute_reply":"2024-11-30T19:30:41.090997Z"}},"outputs":[{"name":"stdout","text":"Collecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting sacrebleu\n  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2024.5.15)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=66d820d904d7fc49eacbd22dc5a54366a998051c64d2cdabeea952b44d4c54fc\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge-score\nInstalling collected packages: torchsummary, portalocker, sacrebleu, rouge-score, evaluate\nSuccessfully installed evaluate-0.4.3 portalocker-3.0.0 rouge-score-0.1.2 sacrebleu-2.4.3 torchsummary-1.5.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Import Library","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nimport re\nimport tensorflow as tf\nimport evaluate\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\n\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel, EncoderDecoderModel, Seq2SeqTrainingArguments, GenerationConfig, get_linear_schedule_with_warmup\nfrom transformers import Seq2SeqTrainer, DataCollatorForSeq2Seq, TrainerCallback, T5Config\n\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\n\nfrom torch.nn import CrossEntropyLoss\nfrom torch.optim import AdamW\nfrom torch.utils.data import TensorDataset\nfrom torchsummary import summary\n\nfrom collections import defaultdict\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-30T19:30:41.094026Z","iopub.execute_input":"2024-11-30T19:30:41.094363Z","iopub.status.idle":"2024-11-30T19:31:04.114448Z","shell.execute_reply.started":"2024-11-30T19:30:41.094330Z","shell.execute_reply":"2024-11-30T19:31:04.113618Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Cleaning Data","metadata":{}},{"cell_type":"code","source":"#Load Data\ndf = pd.read_csv('/kaggle/input/layoutlm/medquad.csv')\n\n# Sampel Data\nprint(\"Data Sample\")\nprint(df.head())\n\n#Null value\nprint(\"Null Value Data\")\nprint(df.isnull().sum())\n\n# List of question words\nquestion_words = ['what', 'who', 'why', 'when', 'where', 'how', 'is', 'are', 'does', 'do', 'can', 'will', 'shall']\n\n# Ensure questions are lowercase for consistent filtering\ndf['question'] = df['question'].str.lower()\n\n# Filter rows where the question starts with a question word\ndf = df[df['question'].str.split().str[0].isin(question_words)]\n\ndf = df.reset_index(drop=True)\n\n# Check for duplicate rows\nduplicates = df.duplicated()\nprint(f\"Number of duplicate rows: {duplicates.sum()}\")\n\n# Remove duplicate rows\ndf = df.drop_duplicates()\n\n# Reset the index after removing duplicates\ndf.reset_index(drop=True, inplace=True)\n\n#Delete Unused column\ndf = df.drop(columns=['source', 'focus_area'])\n\n#Table Info\nprint(\"Table Info\")\nprint(df.info())\n\n# Apply the function\ndf = df.drop_duplicates(subset='question', keep='first').reset_index(drop=True)\ndf = df.drop_duplicates(subset='answer', keep='first').reset_index(drop=True)\n\n#Drop rows with null values\ndf = df.drop_duplicates(subset=['question', 'answer']).reset_index(drop=True)\ndf['question'] = df['question'].fillna('').astype(str)\ndf['answer'] = df['answer'].fillna('').astype(str)\n\n# Removing \"(are)\" in the dataset\ndef clean_text(text):\n    text = re.sub(r\"\\(.*?\\)\", \"\", text)\n    text = re.sub(r'\\s+', ' ', text.strip().lower())\n    return text\n\ndf['question'] = df['question'].apply(clean_text)\ndf['answer'] = df['answer'].apply(clean_text)\n\ndf['question'] = df['question'].str.lower().str.strip().apply(lambda x: re.sub(r'\\s+', ' ', x))\ndf['answer'] = df['answer'].str.lower().str.strip().apply(lambda x: re.sub(r'\\s+', ' ', x))\n\n#Checking again of null values\nprint(\"Null Value Data\")\nprint(df.isnull().sum())\n\n#Check for Unique Data\nprint(f\"Unique questions: {df['question'].nunique()}\")\nprint(f\"Unique answers: {df['answer'].nunique()}\")\n\n#Checking again of the data info\ndf.info()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-30T19:31:04.116022Z","iopub.execute_input":"2024-11-30T19:31:04.116560Z","iopub.status.idle":"2024-11-30T19:31:06.783953Z","shell.execute_reply.started":"2024-11-30T19:31:04.116531Z","shell.execute_reply":"2024-11-30T19:31:06.783009Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Data Sample\n                                 question  \\\n0                What is (are) Glaucoma ?   \n1                  What causes Glaucoma ?   \n2     What are the symptoms of Glaucoma ?   \n3  What are the treatments for Glaucoma ?   \n4                What is (are) Glaucoma ?   \n\n                                              answer           source  \\\n0  Glaucoma is a group of diseases that can damag...  NIHSeniorHealth   \n1  Nearly 2.7 million people have glaucoma, a lea...  NIHSeniorHealth   \n2  Symptoms of Glaucoma  Glaucoma can develop in ...  NIHSeniorHealth   \n3  Although open-angle glaucoma cannot be cured, ...  NIHSeniorHealth   \n4  Glaucoma is a group of diseases that can damag...  NIHSeniorHealth   \n\n  focus_area  \n0   Glaucoma  \n1   Glaucoma  \n2   Glaucoma  \n3   Glaucoma  \n4   Glaucoma  \nNull Value Data\nquestion       0\nanswer         5\nsource         0\nfocus_area    14\ndtype: int64\nNumber of duplicate rows: 48\nTable Info\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 16364 entries, 0 to 16363\nData columns (total 2 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   question  16364 non-null  object\n 1   answer    16359 non-null  object\ndtypes: object(2)\nmemory usage: 255.8+ KB\nNone\nNull Value Data\nquestion    0\nanswer      0\ndtype: int64\nUnique questions: 13844\nUnique answers: 13852\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 13858 entries, 0 to 13857\nData columns (total 2 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   question  13858 non-null  object\n 1   answer    13858 non-null  object\ndtypes: object(2)\nmemory usage: 216.7+ KB\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                 question  \\\n0                      what is glaucoma ?   \n1                  what causes glaucoma ?   \n2     what are the symptoms of glaucoma ?   \n3  what are the treatments for glaucoma ?   \n4          who is at risk for glaucoma? ?   \n\n                                              answer  \n0  glaucoma is a group of diseases that can damag...  \n1  nearly 2.7 million people have glaucoma, a lea...  \n2  symptoms of glaucoma glaucoma can develop in o...  \n3  although open-angle glaucoma cannot be cured, ...  \n4  anyone can develop glaucoma. some people are a...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>what is glaucoma ?</td>\n      <td>glaucoma is a group of diseases that can damag...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>what causes glaucoma ?</td>\n      <td>nearly 2.7 million people have glaucoma, a lea...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>what are the symptoms of glaucoma ?</td>\n      <td>symptoms of glaucoma glaucoma can develop in o...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what are the treatments for glaucoma ?</td>\n      <td>although open-angle glaucoma cannot be cured, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>who is at risk for glaucoma? ?</td>\n      <td>anyone can develop glaucoma. some people are a...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# Architecting Model","metadata":{}},{"cell_type":"code","source":"# Step 1: Load gpt2 model and tokenizer\nmodel_name = \"gpt2\"  \n\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\ntokenizer.padding_side = \"left\"\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\nmodel.config.pad_token_id = tokenizer.eos_token_id\n\n# Configure special tokens\n\n# Print the model architecture\ndef summarize_model_by_type(model):\n    layer_summary = defaultdict(int)\n    param_summary = defaultdict(int)\n\n    for name, module in model.named_modules():\n        layer_type = type(module).__name__\n        layer_summary[layer_type] += 1\n        param_summary[layer_type] += sum(p.numel() for p in module.parameters())\n\n    print(f\"{'Layer Type':<30}{'Count':<10}{'Parameters':<15}\")\n    print(\"=\" * 55)\n    for layer_type, count in layer_summary.items():\n        print(f\"{layer_type:<30}{count:<10}{param_summary[layer_type]:<15,}\")\n\nsummarize_model_by_type(model)\n\n# Step 2: Preprocess function for seq2seq\ndef preprocess_function(df, tokenizer):  \n    # Add more context and formatting\n    inputs = [f\"Answer the following question comprehensively: {q}\" for q in df['question']]\n    targets = [f\"Answer: {a}\" for a in df['answer']]\n\n    # More robust tokenization\n    encodings = tokenizer(\n        inputs, \n        text_target=targets,\n        truncation=True, \n        padding='max_length', \n        max_length=128, \n        return_tensors=\"pt\",\n        add_special_tokens=True\n    )\n\n    return {\n        'input_ids': encodings['input_ids'],\n        'attention_mask': encodings['attention_mask'],\n        'labels': encodings['labels']\n    }\n\n# Metrics tracking function (replaces MetricLoggerCallback)\ndef track_metrics(metrics):\n    tracked_metrics = []\n    \n    def log_metric(metric):\n        tracked_metrics.append(metric)\n        return tracked_metrics\n    \n    return log_metric, tracked_metrics\n\n\n# Step 3: Train-test split\ntrain_df, val_df = train_test_split(df, test_size=0.15, random_state=42)\n\n# Convert to Hugging Face Dataset\ntrain_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\n\n# Preprocess datasets\ntrain_dataset = train_dataset.map(\n    lambda batch: preprocess_function(batch, tokenizer), \n    batched=True,\n    batch_size=32,  \n    remove_columns=train_dataset.column_names,\n    num_proc=1,    \n)\n\nval_dataset = val_dataset.map(\n    lambda batch: preprocess_function(batch, tokenizer),\n    batched=True,\n    batch_size=32,  \n    remove_columns=val_dataset.column_names,\n    num_proc=1,    \n)\n\n# Step 4: Define TrainingArguments\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    save_steps=1000,\n    save_total_limit=2,\n    learning_rate=5e-5,\n    warmup_steps=500,\n    weight_decay=0.01,\n    num_train_epochs=10,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    gradient_accumulation_steps=2,\n    predict_with_generate=True,\n    logging_dir=\"./logs\",\n    logging_steps=100,\n    metric_for_best_model=\"eval_loss\",\n    report_to=\"none\",\n    generation_max_length=178,  \n    generation_num_beams=4,  \n    generation_config=GenerationConfig(\n        pad_token_id=tokenizer.eos_token_id\n    ),\n)\n\n# Step 5: Data collator\ndata_collator = DataCollatorForSeq2Seq(\n    tokenizer=tokenizer, \n    model=model,\n    padding='longest',\n)\n\n# Setup metrics tracking\nlog_metric, tracked_metrics = track_metrics({})\n\n# Load evaluation metrics\nrouge_metric = evaluate.load(\"rouge\")\nbleu_metric = evaluate.load(\"bleu\")\n\n# Step 6: Define compute_metrics\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n\n    if isinstance(predictions, tuple):\n        predictions = predictions[0]\n\n    # Decode predictions and labels\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Normalize text\n    def normalize_text(texts):\n        return [re.sub(r'\\s+', ' ', str(text).lower().strip()) for text in texts]\n\n    normalized_preds = normalize_text(decoded_preds)\n    normalized_labels = normalize_text(decoded_labels)\n\n    # Prepare references for BLEU and ROUGE\n    references = [[label] for label in normalized_labels]\n\n    try:\n        # Compute ROUGE\n        rouge_results = rouge_metric.compute(\n            predictions=normalized_preds,\n            references=references\n        )\n\n        # Compute BLEU\n        bleu_results = bleu_metric.compute(\n            predictions=normalized_preds,\n            references=references\n        )\n\n        # Extract simpler metrics\n        metrics = {\n            'rouge1_fmeasure': rouge_results.get('rouge1', 0), \n            'bleu': bleu_results.get('bleu', 0),  \n        }\n    except Exception as e:\n        print(f\"Error computing metrics: {e}\")\n        metrics = {\n            'rouge1_fmeasure': 0,\n            'bleu': 0,\n        }\n\n    return metrics\n\n# Calculate total training steps\ntotal_steps = len(train_dataset) * training_args.num_train_epochs\n\n# Create optimizer\noptimizer = AdamW(model.parameters(), lr=5e-5)\n\n# Create learning rate scheduler\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, \n    num_warmup_steps=1000, \n    num_training_steps=total_steps\n)\n    \n# Step 7: Trainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    optimizers=(optimizer, scheduler)\n)\n\n# Step 8: Train and Save Model\ntrainer.train()\ntrainer.save_model(\"./gpt2_model\")\ntokenizer.save_pretrained(\"./gpt2_tokenizer\")\n\nimport json\nwith open(\"metrics.json\", \"w\") as f:\n    json.dump(tracked_metrics, f)","metadata":{"execution":{"iopub.status.busy":"2024-11-30T19:31:06.786144Z","iopub.execute_input":"2024-11-30T19:31:06.786396Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f032837a5c99463ab30629d52eb09744"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd0e48f6d1f141db9438450855dfa722"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a72a474b57c4b5ba6ab71eb593f8160"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed667a7c55604dd09e85647fea3030fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3868c907335649b980948e8b2814ed7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbf62a687a754d8db553c1cb7a953f9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"becad8e232974abd836ce59357a51d61"}},"metadata":{}},{"name":"stdout","text":"Layer Type                    Count     Parameters     \n=======================================================\nGPT2LMHeadModel               1         124,439,808    \nGPT2Model                     1         124,439,808    \nEmbedding                     2         39,383,808     \nDropout                       37        0              \nModuleList                    1         85,054,464     \nGPT2Block                     12        85,054,464     \nLayerNorm                     25        38,400         \nGPT2SdpaAttention             12        28,348,416     \nConv1D                        48        85,017,600     \nGPT2MLP                       12        56,669,184     \nNewGELUActivation             12        0              \nLinear                        1         38,597,376     \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/11779 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2b979cac8564946a19863079bdd337a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2079 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdd3f173062d4326836759b9fd5cfa5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5506b9503aa5460ebed06c9a30016cb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efc721cd865f42ea8841f28a2471e426"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d421700b98b04e72bc12f5304d6635cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc74024c81bf4873aaab46c9d7ced08a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='378' max='1840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 378/1840 20:16 < 1:18:50, 0.31 it/s, Epoch 2.04/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1 Fmeasure</th>\n      <th>Bleu</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>9.872500</td>\n      <td>6.334852</td>\n      <td>0.220851</td>\n      <td>0.034590</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>6.196200</td>\n      <td>5.927448</td>\n      <td>0.218005</td>\n      <td>0.034093</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"# Show graphics","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport json\n\n# Load saved metrics\nwith open(\"metrics.json\", \"r\") as f:\n    metrics = json.load(f)\n\n# Extract specific metrics\nsteps = [m[\"step\"] for m in metrics]\nexact_match = [m.get(\"eval_exact_match\", 0) for m in metrics]\nrouge1 = [m.get(\"eval_rouge1\", 0) for m in metrics]\nrougeL = [m.get(\"eval_rougeL\", 0) for m in metrics]\nbleu = [m.get(\"eval_bleu\", 0) for m in metrics]\n\n# Plot metrics\nplt.figure(figsize=(10, 6))\nplt.plot(steps, exact_match, label=\"Exact Match\", marker=\"o\")\nplt.plot(steps, rouge1, label=\"ROUGE-1\", marker=\"s\")\nplt.plot(steps, rougeL, label=\"ROUGE-L\", marker=\"^\")\nplt.plot(steps, bleu, label=\"BLEU\", marker=\"x\")\n\n# Configure the plot\nplt.xlabel(\"Training Step\")\nplt.ylabel(\"Metric Score\")\nplt.title(\"Evaluation Metrics Over Training\")\nplt.legend()\nplt.grid()\nplt.tight_layout()\n\n# Show the plot\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testing using Input","metadata":{}},{"cell_type":"code","source":"# Load the trained T5 model and tokenizer\nmodel_path = \"/kaggle/working/biobert_seq2seq_model\"\ntokenizer_path = \"/kaggle/working/biobert_seq2seq_tokenizer\"\n\ntokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\nmodel = GPT2LMHeadModel.from_pretrained(model_path)\nmodel.eval() \n\ndef generate_response(question):\n    input_ids = tokenizer(f\"question: {question}\", return_tensors=\"pt\").input_ids.to(model.device)\n    outputs = model.generate(\n        input_ids,\n        max_length=128,\n        num_beams=5,  \n        no_repeat_ngram_size=2,  \n        top_k=50,  \n        top_p=0.95,  \n        temperature=1.0  \n    )\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n# Example usage\nresponse = generate_response(\"What is alzheimer ?\")\nprint(response)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}