{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3723297,"sourceType":"datasetVersion","datasetId":2222120},{"sourceId":7639866,"sourceType":"datasetVersion","datasetId":841565},{"sourceId":9177835,"sourceType":"datasetVersion","datasetId":5546853},{"sourceId":9941146,"sourceType":"datasetVersion","datasetId":6112205},{"sourceId":9947105,"sourceType":"datasetVersion","datasetId":6116647}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install important library","metadata":{}},{"cell_type":"code","source":"pip install rouge-score sacrebleu evaluate torchsummary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T18:10:49.786802Z","iopub.execute_input":"2024-12-01T18:10:49.787135Z","iopub.status.idle":"2024-12-01T18:11:02.070207Z","shell.execute_reply.started":"2024-12-01T18:10:49.787103Z","shell.execute_reply":"2024-12-01T18:11:02.069207Z"}},"outputs":[{"name":"stdout","text":"Collecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting sacrebleu\n  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2024.5.15)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=ea00a8046176d0a46467ad52fca35e372cc7ff7361280b1183700bdd6d163ed2\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge-score\nInstalling collected packages: torchsummary, portalocker, sacrebleu, rouge-score, evaluate\nSuccessfully installed evaluate-0.4.3 portalocker-3.0.0 rouge-score-0.1.2 sacrebleu-2.4.3 torchsummary-1.5.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Import Library","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nimport re\nimport tensorflow as tf\nimport evaluate\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\n\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, Seq2SeqTrainingArguments\nfrom transformers import Seq2SeqTrainer, DataCollatorForSeq2Seq, TrainerCallback, T5Config\n\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\n\nfrom torch.nn import CrossEntropyLoss\nfrom torch.optim import AdamW\nfrom torch.utils.data import TensorDataset\nfrom torchsummary import summary\n\nfrom collections import defaultdict\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-12-01T18:11:02.071977Z","iopub.execute_input":"2024-12-01T18:11:02.072327Z","iopub.status.idle":"2024-12-01T18:11:25.398911Z","shell.execute_reply.started":"2024-12-01T18:11:02.072293Z","shell.execute_reply":"2024-12-01T18:11:25.398201Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Cleaning Data","metadata":{}},{"cell_type":"code","source":"#Load Data\ndf = pd.read_csv('/kaggle/input/layoutlm/medquad.csv')\n\n# Sampel Data\nprint(\"Data Sample\")\nprint(df.head())\n\n#Null value\nprint(\"Null Value Data\")\nprint(df.isnull().sum())\n\n# List of question words\nquestion_words = ['what', 'who', 'why', 'when', 'where', 'how', 'is', 'are', 'does', 'do', 'can', 'will', 'shall']\n\n# Ensure questions are lowercase for consistent filtering\ndf['question'] = df['question'].str.lower()\n\n# Filter rows where the question starts with a question word\ndf = df[df['question'].str.split().str[0].isin(question_words)]\n\ndf = df.reset_index(drop=True)\n\n# Check for duplicate rows\nduplicates = df.duplicated()\nprint(f\"Number of duplicate rows: {duplicates.sum()}\")\n\n# Remove duplicate rows\ndf = df.drop_duplicates()\n\n# Reset the index after removing duplicates\ndf.reset_index(drop=True, inplace=True)\n\n#Delete Unused column\ndf = df.drop(columns=['source', 'focus_area'])\n\n#Table Info\nprint(\"Table Info\")\nprint(df.info())\n\n# Apply the function\ndf = df.drop_duplicates(subset='question', keep='first').reset_index(drop=True)\ndf = df.drop_duplicates(subset='answer', keep='first').reset_index(drop=True)\n\n#Drop rows with null values\ndf = df.drop_duplicates(subset=['question', 'answer']).reset_index(drop=True)\ndf['question'] = df['question'].fillna('').astype(str)\ndf['answer'] = df['answer'].fillna('').astype(str)\n\n# Removing \"(are)\" in the dataset\ndef clean_text(text):\n    text = re.sub(r\"\\(.*?\\)\", \"\", text)\n    text = re.sub(r'\\s+', ' ', text.strip().lower())\n    return text\n\ndf['question'] = df['question'].apply(clean_text)\ndf['answer'] = df['answer'].apply(clean_text)\n\ndf['question'] = df['question'].str.lower().str.strip().apply(lambda x: re.sub(r'\\s+', ' ', x))\ndf['answer'] = df['answer'].str.lower().str.strip().apply(lambda x: re.sub(r'\\s+', ' ', x))\n\n#Checking again of null values\nprint(\"Null Value Data\")\nprint(df.isnull().sum())\n\n#Check for Unique Data\nprint(f\"Unique questions: {df['question'].nunique()}\")\nprint(f\"Unique answers: {df['answer'].nunique()}\")\n\n#Checking again of the data info\ndf.info()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-12-01T18:11:25.400022Z","iopub.execute_input":"2024-12-01T18:11:25.400578Z","iopub.status.idle":"2024-12-01T18:11:27.992895Z","shell.execute_reply.started":"2024-12-01T18:11:25.400547Z","shell.execute_reply":"2024-12-01T18:11:27.991910Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Data Sample\n                                 question  \\\n0                What is (are) Glaucoma ?   \n1                  What causes Glaucoma ?   \n2     What are the symptoms of Glaucoma ?   \n3  What are the treatments for Glaucoma ?   \n4                What is (are) Glaucoma ?   \n\n                                              answer           source  \\\n0  Glaucoma is a group of diseases that can damag...  NIHSeniorHealth   \n1  Nearly 2.7 million people have glaucoma, a lea...  NIHSeniorHealth   \n2  Symptoms of Glaucoma  Glaucoma can develop in ...  NIHSeniorHealth   \n3  Although open-angle glaucoma cannot be cured, ...  NIHSeniorHealth   \n4  Glaucoma is a group of diseases that can damag...  NIHSeniorHealth   \n\n  focus_area  \n0   Glaucoma  \n1   Glaucoma  \n2   Glaucoma  \n3   Glaucoma  \n4   Glaucoma  \nNull Value Data\nquestion       0\nanswer         5\nsource         0\nfocus_area    14\ndtype: int64\nNumber of duplicate rows: 48\nTable Info\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 16364 entries, 0 to 16363\nData columns (total 2 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   question  16364 non-null  object\n 1   answer    16359 non-null  object\ndtypes: object(2)\nmemory usage: 255.8+ KB\nNone\nNull Value Data\nquestion    0\nanswer      0\ndtype: int64\nUnique questions: 13844\nUnique answers: 13852\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 13858 entries, 0 to 13857\nData columns (total 2 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   question  13858 non-null  object\n 1   answer    13858 non-null  object\ndtypes: object(2)\nmemory usage: 216.7+ KB\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                 question  \\\n0                      what is glaucoma ?   \n1                  what causes glaucoma ?   \n2     what are the symptoms of glaucoma ?   \n3  what are the treatments for glaucoma ?   \n4          who is at risk for glaucoma? ?   \n\n                                              answer  \n0  glaucoma is a group of diseases that can damag...  \n1  nearly 2.7 million people have glaucoma, a lea...  \n2  symptoms of glaucoma glaucoma can develop in o...  \n3  although open-angle glaucoma cannot be cured, ...  \n4  anyone can develop glaucoma. some people are a...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>what is glaucoma ?</td>\n      <td>glaucoma is a group of diseases that can damag...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>what causes glaucoma ?</td>\n      <td>nearly 2.7 million people have glaucoma, a lea...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>what are the symptoms of glaucoma ?</td>\n      <td>symptoms of glaucoma glaucoma can develop in o...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what are the treatments for glaucoma ?</td>\n      <td>although open-angle glaucoma cannot be cured, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>who is at risk for glaucoma? ?</td>\n      <td>anyone can develop glaucoma. some people are a...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# Architecting Model","metadata":{}},{"cell_type":"code","source":"# Load T5-small model and tokenizer\nmodel_name = \"t5-base\"\nconfig = T5Config.from_pretrained(model_name)\nconfig.dropout_rate = 0.1\nconfig.feed_forward_proj = \"gelu\"  \nmodel = T5ForConditionalGeneration.from_pretrained(\n    model_name, \n    config=config\n)\ntokenizer = T5Tokenizer.from_pretrained(model_name)\n\n# Tie weights explicitly\nmodel.resize_token_embeddings(len(tokenizer))\n\n# Print model architecture summary\n# Print detailed model summary\nprint(\"\\nDetailed Model Summary:\")\nprint(\"=\" * 50)\n\ndef summarize_model_by_type(model):\n    layer_summary = defaultdict(int)\n    param_summary = defaultdict(int)\n\n    for name, module in model.named_modules():\n        layer_type = type(module).__name__\n        layer_summary[layer_type] += 1\n        param_summary[layer_type] += sum(p.numel() for p in module.parameters())\n\n    print(f\"{'Layer Type':<30}{'Count':<10}{'Parameters':<15}\")\n    print(\"=\" * 55)\n    for layer_type, count in layer_summary.items():\n        print(f\"{layer_type:<30}{count:<10}{param_summary[layer_type]:<15,}\")\n\nsummarize_model_by_type(model)\n\n# Preprocess function for seq2seq task\ndef preprocess_function(batch):\n    # Add more context and flexibility\n    inputs = [\n        f\"answer the following question: {q}\" \n        for q in batch['question']\n    ]\n    targets = [f\"{a}\" for a in batch['answer']]\n    \n    model_inputs = tokenizer(\n        inputs,\n        max_length=256,  \n        truncation=True,\n        padding=\"max_length\",\n        return_tensors=\"pt\",\n    )\n    \n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            targets,\n            max_length=128,  # Increased target length\n            truncation=True,\n            padding=\"max_length\",\n            return_tensors=\"pt\",\n        )\n    \n    labels[\"input_ids\"][labels[\"input_ids\"] == tokenizer.pad_token_id] = -100\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\n# Train-test split\ntrain_df, val_df = train_test_split(df, test_size=0.15, random_state=42)\n\n# Convert to Hugging Face Dataset\ntrain_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\n# print('Halo: ',val_dataset.column_names)\n\n# Preprocess datasets\ntrain_dataset = train_dataset.map(\n    preprocess_function,\n    batched=True,\n    batch_size=32,  \n    remove_columns=train_dataset.column_names,\n    num_proc=4,   \n)\n\nval_dataset = val_dataset.map(\n    preprocess_function,\n    batched=True,\n    batch_size=32,  \n    remove_columns=val_dataset.column_names,\n    num_proc=4,  \n)\n\n\n# Training arguments\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    # eval_steps=1000,  \n    # save_steps=1000,  \n    save_total_limit=2,  \n    learning_rate=3e-4,   \n    num_train_epochs=15,   \n    per_device_train_batch_size=16,   \n    per_device_eval_batch_size=16, \n    lr_scheduler_type=\"linear\",  \n    warmup_ratio=0.1,  \n    weight_decay=0.05,\n    predict_with_generate=True,\n    fp16=True,   \n    logging_dir=\"./logs\",\n    logging_steps=50,  \n    # load_best_model_at_end=True,\n    metric_for_best_model=\"BLEU\",\n    greater_is_better=True,\n    report_to=\"none\",\n    gradient_accumulation_steps=1,   \n    max_grad_norm=0.5,\n    optim=\"adamw_torch_fused\",  \n    generation_max_length=64,  \n    generation_num_beams=4,\n    dataloader_num_workers=4,   \n    group_by_length=True, \n    remove_unused_columns=True,\n)\n\ntraining_args.label_smoothing_factor = 0.1\ndata_collator = DataCollatorForSeq2Seq(\n    tokenizer=tokenizer, \n    model=model,  \n    padding='longest',  \n)\n\n# Create function to show exact match, BLEU and ROUGE\ndef compute_metrics(eval_pred, tokenizer):\n    predictions, labels = eval_pred\n    \n    # Decode predictions\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    # Normalize text\n    decoded_preds = [text.strip().lower() for text in decoded_preds]\n    decoded_labels = [text.strip().lower() for text in decoded_labels]\n    \n    # Multiple metrics\n    exact_match = np.mean([p == l for p, l in zip(decoded_preds, decoded_labels)])\n    \n    bleu_metric = evaluate.load(\"bleu\")\n    rouge_metric = evaluate.load(\"rouge\")\n    \n    bleu_score = bleu_metric.compute(\n        predictions=decoded_preds, \n        references=[[label] for label in decoded_labels]\n    )[\"bleu\"]\n    \n    rouge_score = rouge_metric.compute(\n        predictions=decoded_preds, \n        references=decoded_labels\n    )[\"rougeL\"]\n    \n    return {\n        \"exact_match\": exact_match,\n        \"BLEU\": bleu_score,\n        \"ROUGE-L\": rouge_score,\n    }\n\n# Initialize data collator\ndata_collator = DataCollatorForSeq2Seq(\n    tokenizer=tokenizer,\n    model=model,\n    padding='longest',\n    return_tensors=\"pt\"\n)\n\n# Initialize trainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=lambda eval_pred: compute_metrics(eval_pred, tokenizer)\n)\n\n# Train the model\ntrainer.train()\n\n# Save the model and tokenizer\ntrainer.save_model(\"./t5_chatbot_model\")\ntokenizer.save_pretrained(\"./t5_chatbot_tokenizer\")\nmodel_path = \"./t5_chatbot_model.h5\"\ntorch.save(model.state_dict(), model_path)\n\n# Save log history\nlog_history = trainer.state.log_history","metadata":{"execution":{"iopub.status.busy":"2024-12-01T18:13:14.939791Z","iopub.execute_input":"2024-12-01T18:13:14.940541Z","iopub.status.idle":"2024-12-01T19:06:01.625599Z","shell.execute_reply.started":"2024-12-01T18:13:14.940505Z","shell.execute_reply":"2024-12-01T19:06:01.624079Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\nDetailed Model Summary:\n==================================================\nLayer Type                    Count     Parameters     \n=======================================================\nT5ForConditionalGeneration    1         222,882,048    \nEmbedding                     3         24,653,568     \nT5Stack                       2         247,534,848    \nModuleList                    26        396,455,424    \nT5Block                       24        198,227,712    \nT5LayerSelfAttention          24        56,642,304     \nT5Attention                   36        84,935,424     \nLinear                        193       222,833,664    \nT5LayerNorm                   62        47,616         \nDropout                       86        0              \nT5LayerFF                     24        113,264,640    \nT5DenseActDense               24        113,246,208    \nReLU                          24        0              \nT5LayerCrossAttention         12        28,320,768     \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/11779 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e33f4cbe8084dc7be6fc101d084d1e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/2079 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75cd2343ca6f401d9b54003cdeb767f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1081' max='5535' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1081/5535 52:20 < 3:36:04, 0.34 it/s, Epoch 2.93/15]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Exact Match</th>\n      <th>Bleu</th>\n      <th>Rouge-l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.330200</td>\n      <td>3.114490</td>\n      <td>0.000962</td>\n      <td>0.122611</td>\n      <td>0.319197</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3.121000</td>\n      <td>2.933373</td>\n      <td>0.000000</td>\n      <td>0.137266</td>\n      <td>0.336302</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be6251412d1145bf9ef57c285031c6ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f731315eb36404db44f6812573d2cc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08c125fabdb042159d995748099d8278"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3784018eb7584947ac6bea207d0fc560"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 186\u001b[0m\n\u001b[1;32m    175\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m    176\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    177\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m eval_pred: compute_metrics(eval_pred, tokenizer)\n\u001b[1;32m    183\u001b[0m )\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Save the model and tokenizer\u001b[39;00m\n\u001b[1;32m    189\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./t5_chatbot_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2393\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   2388\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2391\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2394\u001b[0m ):\n\u001b[1;32m   2395\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":6},{"cell_type":"markdown","source":"# Show graphics","metadata":{}},{"cell_type":"code","source":"# Extract loss values from log history\ntrain_loss = []\neval_loss = []\neval_bleu = []\neval_exact_match = []\neval_rogue = []\nsteps = []\neval_steps = []\n\nfor log in log_history:\n    if \"loss\" in log:\n        train_loss.append(log[\"loss\"])\n        steps.append(log[\"step\"])\n    if \"eval_loss\" in log:\n        eval_loss.append(log[\"eval_loss\"])\n        eval_steps.append(log[\"step\"])\n    if \"eval_BLEU\" in log:\n        eval_bleu.append(log[\"eval_BLEU\"])\n    if \"eval_ROUGE-L\" in log:\n        eval_bleu.append(log[\"eval_ROUGE-L\"])\n    if \"eval_exact_match\" in log:\n        eval_exact_match.append(log[\"eval_exact_match\"])\n\n# Plot the losses\nplt.figure(figsize=(10, 6))\nplt.plot(steps, train_loss, label=\"Training Loss\", color=\"blue\", marker=\"o\")\nplt.plot(steps[:len(eval_loss)], eval_loss, label=\"Evaluation Loss\", color=\"orange\", marker=\"o\")\nplt.xlabel(\"Training Steps\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training vs Evaluation Loss\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# Plot the BLEU\nplt.figure(figsize=(10, 6))\nplt.plot(eval_bleu, label=\"BLEU\", marker=\"o\", linestyle=\"-\", color=\"green\")\nplt.xlabel(\"Training Steps\")\nplt.ylabel(\"Metric Score\")\nplt.title(\"BLEU Score Over Training Steps\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n# Plot the ROGUE\nplt.figure(figsize=(10, 6))\nplt.plot(eval_bleu, label=\"ROGUE-L\", marker=\"o\", linestyle=\"-\", color=\"red\")\nplt.xlabel(\"Training Steps\")\nplt.ylabel(\"Metric Score\")\nplt.title(\"ROGUE-L Score Over Training Steps\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n# Plot the BLEU\nplt.figure(figsize=(10, 6))\nplt.plot(eval_bleu, label=\"Exact Match\", marker=\"o\", linestyle=\"-\", color=\"black\")\nplt.xlabel(\"Training Steps\")\nplt.ylabel(\"Metric Score\")\nplt.title(\"Exact match Over Training Steps\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T18:11:46.967363Z","iopub.status.idle":"2024-12-01T18:11:46.967774Z","shell.execute_reply.started":"2024-12-01T18:11:46.967593Z","shell.execute_reply":"2024-12-01T18:11:46.967612Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testing using Input","metadata":{}},{"cell_type":"code","source":"# Load the trained T5 model and tokenizer\nmodel_path = \"/kaggle/working/t5_chatbot_model\"\ntokenizer_path = \"/kaggle/working/t5_chatbot_tokenizer\"\n\ntokenizer = T5Tokenizer.from_pretrained(tokenizer_path)\nmodel = T5ForConditionalGeneration.from_pretrained(model_path)\nmodel.eval() \n\ndef generate_response(question):\n    input_ids = tokenizer(f\"question: {question} </s>\", return_tensors=\"pt\").input_ids.to(model.device)\n    outputs = model.generate(\n        input_ids,\n        max_length=128,\n        num_beams=5,  \n        no_repeat_ngram_size=2,  \n        top_k=50,  \n        top_p=0.95,  \n        temperature=1.0  \n    )\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n# Example usage\nresponse = generate_response(\"What is Diabetes ?\")\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-12-01T18:11:46.969560Z","iopub.status.idle":"2024-12-01T18:11:46.969901Z","shell.execute_reply.started":"2024-12-01T18:11:46.969746Z","shell.execute_reply":"2024-12-01T18:11:46.969763Z"},"trusted":true},"outputs":[],"execution_count":null}]}